d--
title: 'Project 2: Modeling, Testing, and Predicting'
author: "Priyanka Kar pk8398"
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
---

```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
```

# Modeling

```{R}
library(readxl)
library(readr)
library(tidyr)
library(tidyverse)
library(cluster)
library(GGally)
library(kableExtra)
library(rstatix)
library(plotROC)
library(glmnet)
library(lmtest)
fish <- read_xlsx("FishData.xlsx")

#Tidying Data
fish$Hours <- fish$Hours %>% replace_na(20)
fish <- fish %>% mutate("Sell Price 1" = NULL, "Sell Price 2" = NULL, "Chance to Dart" = NULL) %>% rename("Price" = "Sell Price 3", "Time Range" = NULL)
fish <- fish %>% mutate("Conditional_Weather"= case_when(Weather == "Any" ~ 0 , Weather == "Rain/Snow" ~ 1 , Weather == "Rain" ~ 1, Weather == "Sunny" ~ 1)) %>% mutate("Weather" = NULL, "Time Range" = NULL) %>% rename('Darting_Intensity' = 'Darting Intesity', 'Darting_Duration' = "Darting Duration", 'Darting_Style' = "Darting Randomness" )

```

- **0. (5 pts)** Introduce your dataset and each of your variables (or just your main variables if you have lots) in a paragraph. What are they measuring? How many observations?

```{R}
glimpse(fish)
```

*My dataset is centered around the different fish that can be caught in the PC game "Stardew Valley". It measures how much each species of fish sells for, what season and geographic location it can be caught in, if there is a special weather condition where the fish is available to be caught, how many hours a day are available to catch the fish, and lastly, different measures describing the fish's movement (separated as type of darting style, intensity of darting movement, duration of each dart, and the overall difficulty of catching the fish). There are 45 observations total, as there are 45 different fish species in the game.*

- **1. (15 pts)** Perform a MANOVA testing whether any of your numeric variables (or a subset of them, if including them all is unreasonable or doesn't make sense) show a mean difference across levels of one of your categorical variables (3). If they do, perform univariate ANOVAs to find response(s) showing a mean difference across groups (3), and perform post-hoc t tests to find which groups differ (3). Discuss the number of tests you have performed, calculate the probability of at least one type I error (if unadjusted), and adjust the significance level accordingly (bonferroni correction) before discussing significant differences (3). Briefly discuss MANOVA assumptions and whether or not they are likely to have been met (no need for anything too in-depth) (2).

```{R}
man1<-manova(cbind(Price, Darting_Intensity, Darting_Duration, Difficulty, Hours)~Location, data=fish)
summary(man1)
```

*Interestingly, the MANOVA test showed that there is a significant mean difference across levels for the numeric variables based on the location fish are available to catch in, with a p value of 0.007. Because it is significant, I will perform a univariate ANOVA test.*

```{R}
summary.aov(man1)
```

*Performing the univariate ANOVA, I found that the response variables that show a mean difference across groups are darting intensity and hours, with p values of 0.009 and 0.002 respectively.*

```{R}
#t-tests
pairwise.t.test(fish$Hours, fish$Location, p.adj= "none")
pairwise.t.test(fish$Darting_Intensity, fish$Location, p.adj= "none")

1-.95^4 #Type 1 Error

.05/9 #Bonferroni Correction

#Covariance matrices for each group for homogeneity
#lapply(split(DVs,group), cov)

#Multivariate normality for each group
ggplot(fish, aes(x = Darting_Intensity, y = Hours)) + geom_point(alpha = .5) + geom_density_2d(h=2) + coord_fixed() + facet_wrap(~Location)
```

*The post-hoc t-tests showed that I conducted 4 hypothesis tests because I performed 1 MANOVA test, 1 univariate ANOVA test, and 2 post-hoc t tests. Therefore, my probability of at least 1 type-1 error is 1-.95^4 = .1855. The bonferroni correction was .05/9=0.006. After taking into consideration the correction, there was a significant difference for hours between the location groups between the lake and the ocean at a value of 0.002, and between the ocean and the mines at a value of 0.0004. Similarly, the only significant difference for darting intensity between the location groups was between the ocean and the mines at a value of 0.0004. I do not think the homogeneity assumption was met because the covariance matrices are very inconsistent between groups. I also do not think the multivariate normality assumption was met because data points for the Lake and Mines locations were specifically very spread out, rather than rounded, and I am unable to identify normality for the Desert location, which only has 2 data points.*

- **2. (10 pts)** Perform some kind of randomization test on your data (that makes sense). The statistic can be anything you want (mean difference, correlation, F-statistic/ANOVA, chi-squared), etc. State null and alternative hypotheses, perform the test, and interpret the results (7). Create a plot visualizing the null distribution and the test statistic (3).

```{R}
#Hypotheses
#H_0= Difficulty of catching a species of fish is the same regardless of whether the fish has a darting style of mixed or smooth.
#H_A= Difficulty of catching a species of fish is different depending on if the fish has a darting style of mixed or smooth.

#Randomization Test
rand_dist<-vector()
for(i in 1:5000){
new<-data.frame(Difficulty=sample(fish$Difficulty),Darting_Style=fish$Darting_Style)
rand_dist[i]<-mean(new[new$Darting_Style=="mixed",]$Difficulty)-
mean(new[new$Darting_Style=="smooth",]$Difficulty)}

#Mean Difference
mean(new[new$Darting_Style=="mixed",]$Difficulty) - mean(new[new$Darting_Style=="smooth",]$Difficulty)

#Plot
{hist(rand_dist,main="",ylab=""); abline(v = c(-13.375, 13.375),col="red")}

#p-value
mean(rand_dist > 13.375 | rand_dist < -13.375)
```

*I wanted to find the mean differences of fish catching difficulty based on the darting style of the fish species, because presumably, some darting styles should make a fish harder to catch than others. I reasoned that fish with a mixed style of darting would be the most unpredictable, and therefore hardest to catch. The smooth darting style also sounded like it could be attached to lower difficulty fish. These are the two categories I compared. My null hypothesis was "Difficulty of catching a species of fish is the same regardless of whether the fish has a darting style of mixed or smooth", and my alternative hypothesis was "Difficulty of catching a species of fish is different depending on if the fish has a darting style of mixed or smooth". After performing the randomization test, I found that the p-value was 0.1702, which is not significant. Therefore, I failed to reject the null hypothesis and concluded that fish catching difficulty is the same regardless of a smooth or mixed darting style.*

- **3. (35 pts)** Build a linear regression model predicting one of your response variables from at least 2 other variables, including their interaction. Mean-center any numeric variables involved in the interaction.

```{R}
#Coefficient Estimates
fit <- lm(Price~ Difficulty, data = fish)
summary(fit)
#Regression Plot
fish%>%ggplot(aes(Difficulty,Price))+geom_point()+geom_smooth(method = 'lm',se=F) + ggtitle("Linear Regression of Fish Catching Difficulty on Selling Price") + xlab("Catching Difficulty") + ylab("Selling Price (G)")
#Assumptions
resid <- fit$residuals
fitted <- fit$fitted.values
shapiro.test(resid) #Normality
bptest(fit) #Homoskedacity
ggplot()+geom_point(aes(fitted,resid))+geom_hline(yintercept=0, col="red") #Linearity
#Regression with Standard Errors
coeftest(fit)
#Proportion of Variation Explained
(sum((fish$Price-mean(fish$Price))^2)-sum(fit$residuals^2))/sum((fish$Price-mean(fish$Price))^2)
```
*The coefficient estimate for difficulty says that for every 1 unit increase in difficulty, selling price increases by 46.35 gold, on average. The normality assumption is not intact because the p-value of 1.065e-11 from the Shapiro-Wilk test means reject the null hypothesis of the true distribution being normal. The homoskedacity assumption is not intact because the p-value of 0.023 is significant, so the homoskedacity null hypothesis is rejected. Lastly, the plot does shows a significant curve of points, so the linearity assumption is not intact After recomputing the regression for robust standard errors, the difficulty coefficient estimate is not significant, even though it appeared significant originally. The proportion of the variation in selling price explained by difficulty of catching the fish is 0.1848.*

```{R}
#Coefficient Estimates
fit2 <- lm(Price~Hours, data= fish)
summary(fit2)
#Regression Plot
fish%>%ggplot(aes(Hours,Price))+geom_point()+geom_smooth(method = 'lm',se=F) + ggtitle("Linear Regression of Hours of Fish Availability on Selling Price") + xlab("Fish Availability (hrs)") + ylab("Selling Price (G)")
#Assumptions
resid <- fit2$residuals
fitted <- fit2$fitted.values
shapiro.test(resid) #Normality
bptest(fit2) #Homoskedacity
ggplot()+geom_point(aes(fitted,resid))+geom_hline(yintercept=0, col="red") #Linearity
#Regression with Standard Errors
coeftest(fit2)
#Proportion of Variation Explained
(sum((fish$Price-mean(fish$Price))^2)-sum(fit2$residuals^2))/sum((fish$Price-mean(fish$Price))^2)
```
*The coefficient estimate for hours says that for every 1 unit increase in hours of fish availability, selling price increases by 34.72 gold, on average. The normality assumption is not intact because the p-value of 9.507e-14 from the Shapiro-Wilk test means reject the null hypothesis of the true distribution being normal. T The homoskedacity assumption is intact because the p-value of 0.85 is not significant, so we fail to reject the homoskedacity null hypothesis. Lastly, the plot does not show a significant curve of points, so the linearity assumption is fine. After recomputing the regression for robust standard errors, the difficulty coefficient estimate is not significant, which is the same as the original regression test, where the results were not significant. The proportion of the variation in selling price explained by difficulty of catching the fish is 0.0042.*

```{R}
#Centering Numeric Variables
fish$Difficulty_c <- fish$Difficulty - mean(fish$Difficulty, na.rm = T)
fish$Hours_c <- fish$Hours - mean(fish$Hours, na.rm = T)
#Coefficient Estimates
fit3 <- lm(Price~Hours_c*Difficulty_c, data= fish)
summary(fit3)
#Regression Plot
fish%>%ggplot(aes(Hours_c*Difficulty_c,Price))+geom_point()+geom_smooth(method = 'lm',se=F) + ggtitle("Linear Regression of the Difficulty and Availability Interaction on Selling Price") + xlab("Interaction of Availability and Difficulty (hrs*G)") + ylab("Selling Price (G)")
#Assumptions
resid <- fit3$residuals
fitted <- fit3$fitted.values
shapiro.test(resid) #Normality
bptest(fit3) #Homoskedacity
ggplot()+geom_point(aes(fitted,resid))+geom_hline(yintercept=0, col="red") #Linearity
#Regression with Standard Errors
coeftest(fit3)
#Proportion of Variation Explained
(sum((fish$Price-mean(fish$Price))^2)-sum(fit3$residuals^2))/sum((fish$Price-mean(fish$Price))^2)
```

*The coefficient estimate for centered hours of availability says that controlling for fish catching difficulty, price increases by 70.61 gold for every 1 hour increase, on average. The coefficient estimate for centered amount of catching difficulty says that controlling for hours of availability, price increases by 47.94 gold for every 1 unit increase in centered difficulty, on average. The coefficient estimate for the interaction between centered hours of availability and centered catching difficulty says that the slope for centered hours of availability by centered catching difficulty on selling price is 0.5637 higher for every 1 unit increase, on average. The normality assumption is not intact because the p-value of 1.139e-11 from the Shapiro-Wilk test means reject the null hypothesis of the true distribution being normal. T The homoskedacity assumption is intact because the p-value of 0.1358 is not significant, so we fail to reject the homoskedacity null hypothesis. Lastly, the plot shows a significant curve of points, so the linearity assumption is not intact After recomputing the regression for robust standard errors, the coefficient estimates are not significant, which is different from the original test because originally the interaction between hours_c and difficulty_c was significant. The proportion of the variation in selling price explained by difficulty of catching the fish is 0.2032.*

- **4. (5 pts)** Rerun same regression model (with the interaction), but this time compute bootstrapped standard errors (either by resampling observations or residuals). Discuss any changes you observe in SEs and p-values using these SEs compared to the original SEs and the robust SEs)

```{R}
boot_dat <- sample_frac(fish, replace = T)
samp_distn <- replicate(5000, {
    boot_dat <- sample_frac(fish, replace = T)
    fit4 <- lm(Price ~ Hours_c*Difficulty_c, data = boot_dat)
    coef(fit4)
})
samp_distn %>% t %>% as.data.frame %>% summarize_all(sd)
```
*The bootstrapped standard errors for resampled observations differed slightly from the robust standard errors, and differed a large amount from the original standard errors. The bootstrapped standard errors would not have altered the fact that these interactions are not significant, because they do not differ much from the robust standard errors, and the p-values accounting for the robust standard errors were not close to significant.*

- **5. (25 pts)** Fit a logistic regression model predicting a binary variable (if you don't have one, make/get one) from at least two explanatory variables (interaction not necessary). 

```{R}
#Coefficient Estimates
fit5 <- glm(Conditional_Weather ~ Season+Location, data = fish, family = "binomial")
summary(fit5)
#Confusion Matrix
prob <- predict(fit5, type = "response")

class_diag<-function(probs,truth){

  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1

  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]

  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))

  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)

  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}

class_diag(prob,fish$Conditional_Weather)
#Density Plot
fish$logit<-predict(fit5)
factor= cut(fish$Conditional_Weather, 2)
fish%>%ggplot(aes(x = logit,color=factor,fill=factor))+geom_density(alpha=.4)+
theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab("predictor (logit)")

#ROC Plot
ROCplot <- ggplot(fit5) + geom_roc(aes(d = Conditional_Weather, m = prob), n.cuts = 0)
ROCplot
calc_auc(ROCplot)#AUC
```
*The intercept predicts the conditional_weather for the spring season and desert location. The coefficient estimates that are negative (Summer, Fall, Winter, All Seasons, Lake Location, Ocean Location, and River Location) are all negative, so they predict conditional weather to a weaker extent than the spring season and desert location. For the Mines Location, the coefficient estimate is positive, so it predicts the conditional_weather slightly better than the spring season and desert location. The accuracy is 0.844, the sensitivity (TPR) is 0.5, the specificity (TNR) is 0.943, the precision (PPV) is 0.714, and the AUC is 0.834. This high auc indicates that Season and Location are good predictors of Conditional Weather. In other words, the season and location that a fish can be caught in are good predictors of whether there is a specific weather condition necessary for catching a fish. From the ROC curve, the auc was 0.834, which, although is lower, is still a good predictor, so the true predictor is still higher for predicted probability than a false one.*

- **6. (25 pts)** Perform a logistic regression predicting the same binary response variable from *ALL* of the rest of your variables (the more, the better!) 
    
```{R}
fish <- fish %>% mutate("logit" = NULL)
#Coefficient Estimates
fit6 <- glm(Conditional_Weather ~ Price+Hours+Darting_Intensity+Darting_Duration+Difficulty, data = fish, family = "binomial")
summary(fit6)

#In-sample Classification Diagnostics
probs <- predict(fit6, type = "response")

class_diag <- function(probs,truth){
#CONFUSION MATRIX: CALCULATE ACCURACY, TPR, TNR, PPV
  
if(is.character(truth)==TRUE) truth<-as.factor(truth)
if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1

tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),factor(truth, levels=c(0,1)))
acc=sum(diag(tab))/sum(tab)
sens=tab[2,2]/colSums(tab)[2]
spec=tab[1,1]/colSums(tab)[1]
ppv=tab[2,2]/rowSums(tab)[2]
f1=2*(sens*ppv)/(sens+ppv)

#CALCULATE EXACT AUC
ord<-order(probs, decreasing=TRUE)
probs <- probs[ord]; truth <- truth[ord]

TPR=cumsum(truth)/max(1,sum(truth)) 
FPR=cumsum(!truth)/max(1,sum(!truth))

dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
n <- length(TPR)
auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

data.frame(acc,sens,spec,ppv,f1,auc)
}
class_diag(probs,fish$Conditional_Weather)

#10-fold sub-sampling and out-of-sample classification diagnostics
set.seed(123)
k=10

data1<-fish[sample(nrow(fish)),] #put dataset in random order
folds<-cut(seq(1:nrow(fish)),breaks=k,labels=F) #create folds

diags<-NULL
for(i in 1:k){          # FOR EACH OF 10 FOLDS
  train<-data1[folds!=i,] # CREATE TRAINING SET
  test<-data1[folds==i,]  # CREATE TESTING SET

  truth<-test$Conditional_Weather

  fit7 <- glm(Conditional_Weather ~ Price+Hours+Darting_Intensity+Darting_Duration+Difficulty, data=train, family="binomial")
  probs<- predict(fit7 , type="response", newdata=test)

  diags<-rbind(diags,class_diag(probs,truth)) #CV DIAGNOSTICS FOR EACH FOLD
}

summarize_all(diags,mean) #AVERAGE THE DIAGNOSTICS ACROSS THE 10 FOLDS
```
*The in-sample classification diagnostics had accuracy as 0.844, the sensitivity (TPR) as 0.4, the specificity (TNR) as 0.971, the precision (PPV) as 0.8, and the AUC as 0.783. After doing the 10-fold sub-sampling, my out-of-sample classification diagnostics had accuracy as 0.765, did not have sensitivity diagnostic, had a specificity of 0.917, did not have a precision diagnostic, and had an auc of 0.408.*

```{R}
set.seed(123)

fish_resp <- as.matrix(fish$Conditional_Weather)
fish_preds <- model.matrix(Conditional_Weather ~ -1 + ., data = fish)
cv.lasso <- cv.glmnet(x = fish_preds, y = fish_resp, 
    family = "binomial")
lasso_fit <- glmnet(x = fish_preds[, -1], y = fish_resp[, 1], 
    family = "binomial", lambda = cv.lasso$lambda.1se)
coef(lasso_fit)
set.seed(123)
k=10
data <- fish %>% sample_frac  #put rows of dataset in random order
folds <- ntile(1:nrow(data), n = 10)  #create fold labels
diags <- NULL
for (i in 1:k) {
    train <- data[folds != i, ]  #create training set (all but fold i)
    test <- data[folds == i, ]  #create test set (just fold i)
    truth <- test$Conditional_Weather  #save truth labels from fold i
    fit8 <- glm(Conditional_Weather ~ Darting_Duration, family = "binomial", data = train)
    probs <- predict(fit8, newdata = test, type = "response")
    diags <- rbind(diags, class_diag(probs, truth))
}
diags %>% summarize_all(mean)
```
*The auc after accounting for the lasso variables increased to 0.433, so darting duration predicts whether there needs to be a specific weather condition to catch a fish better than all of the variables combined (which had a lower auc of 0.408). However, the auc still indicates this is a very poor predictor.*
...





++